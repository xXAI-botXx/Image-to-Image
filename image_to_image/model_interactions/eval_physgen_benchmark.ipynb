{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72115f71",
   "metadata": {},
   "source": [
    "# Evaluation of 1 Model With Physgen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28edf180",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params_path = \"../../checkpoints/best_checkpoint.pth\"\n",
    "\n",
    "# Output Paths -> will get cleared!!\n",
    "output_base_dir = \"../../data/eval\"\n",
    "\n",
    "# Data\n",
    "physgen_variation = \"sound_reflection\"    # sound_baseline, sound_reflection, sound_diffraction, sound_combined\n",
    "input_type = \"osm\"  # osm, base_simulation\n",
    "output_type = \"standard\"  # standard, complex_only\n",
    "fake_rgb_output = False\n",
    "make_14_dividable_size = False\n",
    "reflexion_channels = False\n",
    "reflexion_steps = 36\n",
    "reflexions_as_channels = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95fad5b",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ee2f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path += \".\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4196a429",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import re\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "import cv2\n",
    "\n",
    "import img_phy_sim as ips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac171a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d59a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef60814",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.abspath(\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f357709f",
   "metadata": {},
   "source": [
    "### Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca45ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = os.path.join(output_base_dir, \"raw\")\n",
    "output_dir_cleaned = os.path.join(output_base_dir, \"cleaned\")\n",
    "output_dir_evaluation = os.path.join(output_base_dir, \"eval_results\")\n",
    "\n",
    "def clear_path(path):\n",
    "    if os.path.exists(path):\n",
    "        shutil.rmtree(path)\n",
    "        print(f\"Cleaned path:'{path}'\")\n",
    "    else:\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "\n",
    "clear_path(output_dir)\n",
    "clear_path(output_dir_cleaned)\n",
    "clear_path(output_dir_evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107b7fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img, title=None, image_width=10, axis=False,\n",
    "           color_space=\"RGB\", cmap=None, cols=1, save_to=None,\n",
    "           hspace=0.2, wspace=0.2,\n",
    "           use_original_sytle=False, invert=False):\n",
    "    \"\"\"\n",
    "    Visualizes one or multiple images.\n",
    "\n",
    "    Image will be reshaped: [batch_size/images, width, height, channels]\n",
    "\n",
    "    ---\n",
    "    Parameters:\n",
    "    - img : np.ndarray\n",
    "        Images/Images with [width, height, channels] or for multiple: [batch_size/images, width, height, channels].\n",
    "    - title : str, optional (default=None)\n",
    "        Title of the whole plot.\n",
    "    - image_width : int, optional (default=5)\n",
    "        Width of one image in the plot.\n",
    "    - axis : bool, optional (default=False)\n",
    "        Whether to print the axis of the images or not.\n",
    "    - color_space : str, optional (default=\"RGB\")\n",
    "        The colorspace of the image: RGB, BGR, gray, HSV.\n",
    "    - cmap : str, optional (default=None)\n",
    "        Which cmap to use. Check all cmaps here out: https://matplotlib.org/stable/users/explain/colors/colormaps.html\n",
    "    - cols : int, optional (default=1)\n",
    "        Amount of columns in the plot.\n",
    "    - save_to : str, optional (default=None)\n",
    "        Path where to save the result image.\n",
    "    - hspace : float, optional (default=0.01)\n",
    "        Horizontal space between the images.\n",
    "    - wspace : float, optional (default=0.01)\n",
    "        Vertical space between the images.\n",
    "    - use_original_sytle : bool, optonial (default=False)\n",
    "        Whether the plot should use the current active matplotlib style or choosing a own one. \n",
    "    - invert : bool, optional (default=False)\n",
    "        Whether to invert the images or not.\n",
    "    \"\"\"\n",
    "    original_style = plt.rcParams.copy()\n",
    "\n",
    "    img_shape = img.shape\n",
    "    print(f\"Got images with shape: {img_shape}\")\n",
    "\n",
    "    # tranform the image to the right form\n",
    "    if len(img_shape) == 2:\n",
    "        img = np.reshape(img, shape=(1, img.shape[0], img.shape[1], 1))\n",
    "    elif len(img_shape) == 3:\n",
    "        # check if multiple gray images or multiple images with channel\n",
    "        # if img.shape[2] < img.shape[0] and img.shape[1] == img.shape[2]:\n",
    "        img = np.reshape(img, shape=(1, img.shape[0], img.shape[1], img.shape[2]))\n",
    "        # else:\n",
    "        #     # there could be cases where this is wrong\n",
    "        #     img = np.reshape(img, shape=(img.shape[0], img.shape[1], img.shape[2], 1))\n",
    "    elif len(img_shape) != 4:\n",
    "        raise ValueError(f\"Image(s) have wrong shape! Founded shape: {img.shape}.\")\n",
    "\n",
    "    print(f\"Transformed shape to: {img_shape}\")\n",
    "\n",
    "    # invert images\n",
    "    if invert:\n",
    "        print(\"Invert images...\")\n",
    "        max_value = 2**(img.dtype.itemsize * 8) -1\n",
    "        scaling_func = lambda x: max_value - x\n",
    "        img = np.apply_along_axis(scaling_func, axis=0, arr=img)\n",
    "\n",
    "    # Set visualization settings\n",
    "    # aspect_ratio_width = img.shape[1] / img.shape[2]\n",
    "    aspect_ratio = img.shape[2] / img.shape[1]\n",
    "\n",
    "    n_images = img.shape[0]\n",
    "    rows = n_images//cols + int(n_images % cols > 0)\n",
    "\n",
    "    width = int(image_width * cols)\n",
    "    height = int(image_width * rows * aspect_ratio)\n",
    "\n",
    "    # set plt style\n",
    "    if not use_original_sytle:\n",
    "        plt_style = 'seaborn-v0_8' if 'seaborn-v0_8' in plt.style.available else np.random.choice(plt.style.available)\n",
    "        plt.style.use(plt_style)\n",
    "        print(f\"Using '{plt_style}' plotting style.\")\n",
    "\n",
    "    # plotting\n",
    "    print(f\"Making you a beautiful plot...\")\n",
    "    fig, ax = plt.subplots(nrows=rows, ncols=cols, figsize=(width, height))\n",
    "    try:\n",
    "        ax = ax.ravel()\n",
    "    except AttributeError:\n",
    "        ax = [ax]\n",
    "    fig.subplots_adjust(hspace=hspace, wspace=wspace)\n",
    "    if type(title) == str:\n",
    "        fig.suptitle(title, fontsize=128, y=0.95)\n",
    "\n",
    "    for idx in range(len(ax)):\n",
    "        cur_ax = ax[idx]\n",
    "\n",
    "        if idx >= len(img):\n",
    "            cur_ax.axis(\"off\")\n",
    "            continue\n",
    "\n",
    "        cur_img = img[idx]\n",
    "\n",
    "        if color_space.lower() == \"bgr\":\n",
    "            cur_img = cv2.cvtColor(cur_img, cv2.COLOR_BGR2RGB)\n",
    "            used_cmap = None\n",
    "        elif color_space.lower() == \"rgb\":\n",
    "            cur_img = cur_img\n",
    "            used_cmap = None\n",
    "        elif color_space.lower() == \"hsv\":\n",
    "            cur_img = cv2.cvtColor(cur_img, cv2.COLOR_HSV2RGB)\n",
    "            used_cmap = None\n",
    "        elif color_space.lower() in [\"gray\", \"grey\", \"g\"]:\n",
    "            if len(cur_img.shape) == 3 and cur_img.shape[2]:\n",
    "                cur_img = cv2.cvtColor(cur_img, cv2.COLOR_RGB2GRAY)\n",
    "            else:\n",
    "                cur_img = cur_img\n",
    "            print(cur_img.shape)\n",
    "            used_cmap = \"gray\"\n",
    "\n",
    "        if cmap:\n",
    "            used_cmap = cmap\n",
    "\n",
    "        if type(title) in [list, tuple]:\n",
    "            cur_ax.set_title(title[idx], fontsize=64)\n",
    "        if axis == False:\n",
    "            cur_ax.axis(\"off\")\n",
    "\n",
    "        cur_ax.imshow(cur_img, cmap=used_cmap)\n",
    "\n",
    "    if save_to:\n",
    "        os.makedirs(os.path.split(save_to)[0], exist_ok=True)\n",
    "        fig.savefig(save_to, dpi=300)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    if not use_original_sytle:\n",
    "        # reset to original plt style\n",
    "        plt.rcParams.update(original_style)\n",
    "\n",
    "def show_images(image_paths:list, title=None, image_width=5, axis=False,\n",
    "                color_space=\"gray\", cmap=None, \n",
    "                cols=2, save_to=None,\n",
    "                hspace=0.01, wspace=0.01,\n",
    "                use_original_sytle=False, invert=False):\n",
    "    \"\"\"\n",
    "    Visulalizes/shows one or multiple images.\n",
    "\n",
    "    ---\n",
    "    Parameters:\n",
    "    - image_paths : List[str]\n",
    "        List of paths to the images which should get visualized.\n",
    "    - title : str, optional (default=None)\n",
    "        Title of the whole plot.\n",
    "    - image_width : int, optional (default=5)\n",
    "        Width of one image in the plot.\n",
    "    - axis : bool, optional (default=False)\n",
    "        Whether to print the axis of the images or not.\n",
    "    - color_space : str, optional (default=\"RGB\")\n",
    "        The colorspace of the image: RGB, BGR, gray, HSV.\n",
    "    - cmap : str, optional (default=None)\n",
    "        Which cmap to use. Check all cmaps here out: https://matplotlib.org/stable/users/explain/colors/colormaps.html\n",
    "    - cols : int, optional (default=1)\n",
    "        Amount of columns in the plot.\n",
    "    - save_to : str, optional (default=None)\n",
    "        Path where to save the result image.\n",
    "    - hspace : float, optional (default=0.01)\n",
    "        Horizontal space between the images.\n",
    "    - wspace : float, optional (default=0.01)\n",
    "        Vertical space between the images.\n",
    "    - use_original_sytle : bool, optonial (default=False)\n",
    "        Whether the plot should use the current active matplotlib style or choosing a own one. \n",
    "    - invert : bool, optional (default=False)\n",
    "        Whether to invert the images or not.\n",
    "    \"\"\"\n",
    "    if color_space.lower() == \"rgb\":\n",
    "        images = np.array([cv2.cvtColor(cv2.imread(img), cv2.COLOR_BGR2RGB) for img in image_paths])\n",
    "    elif color_space.lower() == \"hsv\":\n",
    "        images = np.array([cv2.cvtColor(cv2.imread(img), cv2.COLOR_BGR2HSV) for img in image_paths])\n",
    "    else:\n",
    "        images = np.array([cv2.imread(img) for img in image_paths])\n",
    "    imshow(images, title=title, image_width=image_width, axis=axis,\n",
    "           color_space=color_space, cmap=cmap, cols=cols, save_to=save_to,\n",
    "           hspace=hspace, wspace=wspace,\n",
    "           use_original_sytle=use_original_sytle, invert=invert)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1583ad16",
   "metadata": {},
   "source": [
    "### Run Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cec9282",
   "metadata": {},
   "outputs": [],
   "source": [
    "command = (\n",
    "  f\"python ../../main.py \"\n",
    "  f\"--mode test \"\n",
    "  f\"--output_dir {output_dir} \"\n",
    "  f\"--model_params_path {model_params_path} \"\n",
    "  f\"--data_variation {physgen_variation} \"\n",
    "  f\"--input_type {input_type} \"\n",
    "  f\"--output_type {output_type} \"\n",
    ")\n",
    "\n",
    "if fake_rgb_output:\n",
    "    command += f\"--fake_rgb_output \"\n",
    "\n",
    "if make_14_dividable_size:\n",
    "    command += f\"--make_14_dividable_size \"\n",
    "\n",
    "if reflexion_channels:\n",
    "    command += f\"--reflexion_channels \"\n",
    "    command += f\"--reflexion_steps {reflexion_steps} \"\n",
    "    if reflexions_as_channels:\n",
    "        command += f\"--reflexions_as_channels \"\n",
    "\n",
    "# Finally run it\n",
    "!{command}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9c413c",
   "metadata": {},
   "outputs": [],
   "source": [
    "command = (\n",
    "  f\"python ../../main.py \"\n",
    "  f\"--mode inference \"\n",
    "  f\"--output_dir {output_dir} \"\n",
    "  f\"--model_params_path {model_params_path} \"\n",
    "  f\"--data_variation {physgen_variation} \"\n",
    "  f\"--input_type {input_type} \"\n",
    "  f\"--output_type {output_type} \"\n",
    "  f\"--batch_size 1 \"\n",
    ")\n",
    "\n",
    "if fake_rgb_output:\n",
    "    command += f\"--fake_rgb_output \"\n",
    "\n",
    "if make_14_dividable_size:\n",
    "    command += f\"--make_14_dividable_size \"\n",
    "\n",
    "if reflexion_channels:\n",
    "    command += f\"--reflexion_channels \"\n",
    "    command += f\"--reflexion_steps {reflexion_steps} \"\n",
    "    if reflexions_as_channels:\n",
    "        command += f\"--reflexions_as_channels \"\n",
    "\n",
    "# Finally run it\n",
    "!{command}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46a0516",
   "metadata": {},
   "source": [
    "### Extract Test Predictions\n",
    "\n",
    "Sort the predictions in sub folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfdddfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python ../utils/eval_extractor.py \\\n",
    "    --evaluation_path {output_dir} \\\n",
    "    --target_path {output_dir_cleaned}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7849e54",
   "metadata": {},
   "source": [
    "### Calc Eval metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861533a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python ../utils/physgen_benchmark.py \\\n",
    "    --data_dir {output_dir_cleaned}/real \\\n",
    "    --pred_dir {output_dir_cleaned}/pred \\\n",
    "    --osm_dir {output_dir_cleaned}/osm \\\n",
    "    --output {output_dir_evaluation}/evaluation.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49c3f50",
   "metadata": {},
   "source": [
    "### Show Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96137cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_model_1_name = f'MAE'\n",
    "los_mae_model_1_name = f'LoS_MAE'\n",
    "nlos_mae_model_1_name = f'NLoS_MAE'\n",
    "mape_model_1_name = f'MAPE'\n",
    "los_wmape_model_1_name = f'LoS_wMAPE'\n",
    "nlos_wmape_model_1_name = f'NLoS_wMAPE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2b0759",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.read_csv(f\"{output_dir_evaluation}/evaluation.csv\")\n",
    "# df_1 = df_1.drop(columns=[\"LoS_MAE\", \"NLoS_MAE\", \"LoS_wMAPE\", \"NLoS_wMAPE\"])\n",
    "df_1 = df_1.rename(columns={'MAE': mae_model_1_name, \n",
    "                            'LoS_MAE': los_mae_model_1_name,\n",
    "                            'NLoS_MAE': nlos_mae_model_1_name,\n",
    "                            'MAPE':mape_model_1_name,\n",
    "                            'LoS_wMAPE': los_wmape_model_1_name,\n",
    "                            'NLoS_wMAPE': nlos_wmape_model_1_name\n",
    "                            }\n",
    "                   )\n",
    "# extract sample_ids\n",
    "sample_id_series = df_1[\"sample_id\"].str.extract(r'^(\\d+)_')[0]\n",
    "if sample_id_series.isna().sum() > 1:\n",
    "    sample_id_series = df_1[\"sample_id\"].str.extract(r'(\\d+)')[0]\n",
    "if sample_id_series.isna().sum() > 1:\n",
    "    raise ValueError(f\"Found {sample_id_series.isna().sum()} Nans\")\n",
    "df_1[\"sample_id\"] = sample_id_series\n",
    "print(\"Nan found in sample ids:\", df_1[\"sample_id\"].isna().sum())\n",
    "df_1 = df_1.dropna(subset=[\"sample_id\"])\n",
    "df_1[\"sample_id\"] = df_1[\"sample_id\"].astype(int)\n",
    "merged_df = df_1\n",
    "df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385206db",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_style = 'seaborn-v0_8' if 'seaborn-v0_8' in plt.style.available else np.random.choice(plt.style.available)\n",
    "plt.style.use(plt_style)\n",
    "print(f\"Using '{plt_style}' plotting style.\")\n",
    "\n",
    "values_0 = [\n",
    "    merged_df[mae_model_1_name],\n",
    "    merged_df[los_mae_model_1_name],\n",
    "    merged_df[nlos_mae_model_1_name],\n",
    "]\n",
    "\n",
    "labels_0 = [\n",
    "    \"MAE\",\n",
    "    \"NLoS MAE\",\n",
    "    \"LoS MAE\"\n",
    "]\n",
    "\n",
    "values_1 = [\n",
    "    merged_df[mape_model_1_name],\n",
    "    merged_df[los_wmape_model_1_name],\n",
    "    merged_df[nlos_wmape_model_1_name]\n",
    "]\n",
    "\n",
    "labels_1 = [\n",
    "    \"MAPE\",\n",
    "    \"LoS wMAPE\",\n",
    "    \"NLoS wMAPE\"\n",
    "]\n",
    "\n",
    "fig, ax = plt.subplots(nrows=2, ncols=1, figsize=(12, 12))\n",
    "ax[0].boxplot(values_0, notch=False)\n",
    "ax[0].set_xticks(range(1, len(labels_0) + 1))\n",
    "ax[0].set_xticklabels(labels_0, rotation=15)\n",
    "ax[0].set_title(\"Error Metrics Distribution\")\n",
    "\n",
    "ax[1].boxplot(values_1, notch=False)\n",
    "ax[1].set_xticks(range(1, len(labels_1) + 1))\n",
    "ax[1].set_xticklabels(labels_1, rotation=15)\n",
    "ax[1].set_title(\"Error Metrics Distribution\")\n",
    "\n",
    "\n",
    "\n",
    "# print(f\"\\nMAE\\n    - {model_1}: {merged_df[mae_model_1_name].mean():>0.2f}\")\n",
    "# print(f\"\\nMAPE\\n    - {model_1}: {merged_df[mape_model_1_name].mean():>0.2f}\")\n",
    "\n",
    "print(f\"\\nLoS MAE: {merged_df[los_mae_model_1_name].mean():>0.2f}\")\n",
    "print(f\"\\nNLoS MAE: {merged_df[nlos_mae_model_1_name].mean():>0.2f}\")\n",
    "print(f\"\\nLoS wMAPE: {merged_df[los_wmape_model_1_name].mean():>0.2f}\")\n",
    "print(f\"\\nNLoS wMAPE: {merged_df[nlos_wmape_model_1_name].mean():>0.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ddf2ca",
   "metadata": {},
   "source": [
    "Example Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac212906",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "def get_unique_hsv_cmap():\n",
    "    unique_hsv_map = plt.get_cmap(\"hsv\")(np.linspace(0, 1, 256))    # np.arange(0, 256)\n",
    "    hsv_map = plt.get_cmap(\"hsv\")\n",
    "    for cur_idx in range(256):\n",
    "        r, g, b, a = hsv_map(cur_idx)\n",
    "        if r > 0.99 and g < (170/255):\n",
    "            gray_value = cur_idx*8 / 255.0\n",
    "            unique_hsv_map[cur_idx] = (gray_value, gray_value, gray_value, 1.0)\n",
    "        else:\n",
    "            break\n",
    "    unique_hsv = ListedColormap(unique_hsv_map)\n",
    "    plt.colormaps.register(name=\"unique_hsv\", cmap=unique_hsv, force=True)\n",
    "    return unique_hsv\n",
    "\n",
    "get_unique_hsv_cmap()\n",
    "plt.get_cmap(\"unique_hsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1e1dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_same_pred_real_samples(pred_path:str, real_path:str, input_path:str, n_samples:int, ids=None):\n",
    "    if not ids:\n",
    "        # choose n random samples\n",
    "        samples = random.sample(os.listdir(pred_path), n_samples)\n",
    "        pred_samples = [os.path.join(pred_path, cur_image) for cur_image in samples]\n",
    "\n",
    "        # get the used id's\n",
    "        ids = []\n",
    "        for cur_image in samples:\n",
    "            cur_id = re.findall(r'\\d+', string=cur_image)\n",
    "            if len(cur_id) <= 0:\n",
    "                raise ValueError(f\"One image has no ID: {cur_image}\")\n",
    "            cur_id = cur_id[-1]\n",
    "            ids += [cur_id]\n",
    "    else:\n",
    "        # get pred image\n",
    "        pred_image_samples = []\n",
    "        for target_id in ids:\n",
    "            found = False\n",
    "            for cur_image in os.listdir(real_path):\n",
    "                cur_id = re.findall('\\d+', string=cur_image)\n",
    "                if len(cur_id) > 0:\n",
    "                    cur_id = cur_id[-1]\n",
    "                    if cur_id == target_id:\n",
    "                        pred_image_samples += [cur_image]\n",
    "                        found = True\n",
    "                        break\n",
    "\n",
    "            if not found:\n",
    "                raise ValueError(f\"Does not found pred image with id: {target_id}\")\n",
    "        pred_samples = [os.path.join(pred_path, cur_image) for cur_image in pred_image_samples]\n",
    "\n",
    "    # get real image\n",
    "    real_image_samples = []\n",
    "    for target_id in ids:\n",
    "        found = False\n",
    "        for cur_image in os.listdir(real_path):\n",
    "            cur_id = re.findall('\\d+', string=cur_image)\n",
    "            if len(cur_id) > 0:\n",
    "                cur_id = cur_id[-1]\n",
    "                if cur_id == target_id:\n",
    "                    real_image_samples += [cur_image]\n",
    "                    found = True\n",
    "                    break\n",
    "\n",
    "        if not found:\n",
    "            raise ValueError(f\"Does not found real image with id: {target_id}\")\n",
    "\n",
    "    target_samples = [os.path.join(real_path, cur_image) for cur_image in real_image_samples]\n",
    "\n",
    "    # get real image\n",
    "    input_image_samples = []\n",
    "    if input_path:\n",
    "        for target_id in ids:\n",
    "            found = False\n",
    "            for cur_image in os.listdir(input_path):\n",
    "                cur_id = re.findall('\\d+', string=cur_image)\n",
    "                if len(cur_id) > 0:\n",
    "                    cur_id = cur_id[-1]\n",
    "                    if cur_id == target_id:\n",
    "                        input_image_samples += [cur_image]\n",
    "                        found = True\n",
    "                        break\n",
    "\n",
    "            if not found:\n",
    "                raise ValueError(f\"Does not found input image with id: {target_id}\")\n",
    "\n",
    "    input_samples = [os.path.join(input_path, cur_image) for cur_image in input_image_samples]\n",
    "\n",
    "    return input_samples, target_samples, pred_samples, ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ad217c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(ax, path, title=\"\", sub_image=None, cmap=\"turbo\", plot=True, normalize=True, vmin=0.0, vmax=1.0):\n",
    "    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE).astype(np.float32)\n",
    "    # print(\"\\n\", title, img.max())\n",
    "    # print(\"\\n\", title, img.min())\n",
    "    img = 255 - img\n",
    "    # print(img.max())\n",
    "\n",
    "    if sub_image:\n",
    "        img_2 = cv2.imread(sub_image, cv2.IMREAD_GRAYSCALE).astype(np.float32)\n",
    "        img_2 = 255 - img_2\n",
    "\n",
    "        assert img_2.shape == img.shape, \"Shape mismatch\"\n",
    "        img = np.abs(img - img_2)\n",
    "        # img = img - img_2\n",
    "        # img[img < 0] = img[img < 0] * -1\n",
    "\n",
    "    # print(title, img.max())\n",
    "\n",
    "    # normalize\n",
    "    if normalize:\n",
    "        img = img / 255.0\n",
    "        if sub_image:\n",
    "            img_2 = img_2 / 255.0\n",
    "\n",
    "    # print(title, img.max())\n",
    "\n",
    "    if plot:\n",
    "        ax.axis(\"off\")\n",
    "        color_ax = ax.imshow(img, cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "        ax.set_title(title)\n",
    "        plt.colorbar(color_ax, ax=ax, fraction=0.046, pad=0.04)\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886b7a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 3\n",
    "\n",
    "input_samples, real, pred_model, ids = get_same_pred_real_samples(f\"{output_dir_cleaned}/pred\",\n",
    "                                                                  f\"{output_dir_cleaned}/real\",\n",
    "                                                                  f\"{output_dir_cleaned}/osm\",\n",
    "                                                                  n_samples)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(nrows=n_samples, ncols=4, figsize=(4*4, n_samples*4))\n",
    "# ax = ax.ravel()\n",
    "\n",
    "ax_idx = 0\n",
    "\n",
    "for idx, cur_path in enumerate(input_samples):\n",
    "    plot(ax[idx][0], path=cur_path, title=f\"Input\", cmap=\"gray\")\n",
    "\n",
    "for idx, cur_path in enumerate(pred_model):\n",
    "    plot(ax[idx][1], path=cur_path, title=f\"Model Prediction\")  #, vmax=100)\n",
    "\n",
    "for idx, cur_path in enumerate(real):\n",
    "    plot(ax[idx][2], path=cur_path, title=f\"Ground Truth\")  # , vmax=100)\n",
    "\n",
    "for idx, cur_path in enumerate(pred_model):\n",
    "    plot(ax[idx][3], path=cur_path, title=f\"Difference\", sub_image=real[idx])\n",
    "\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640465a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=n_samples, ncols=4, figsize=(4*4, n_samples*4))\n",
    "# ax = ax.ravel()\n",
    "\n",
    "ax_idx = 0\n",
    "\n",
    "cur_cmap = \"nipy_spectral\"\n",
    "\n",
    "for idx, cur_path in enumerate(input_samples):\n",
    "    plot(ax[idx][0], path=cur_path, title=f\"Input\", cmap=\"gray\")\n",
    "\n",
    "for idx, cur_path in enumerate(pred_model):\n",
    "    plot(ax[idx][1], path=cur_path, title=f\"Model Prediction\", cmap=cur_cmap)  #, vmax=100)\n",
    "\n",
    "for idx, cur_path in enumerate(real):\n",
    "    plot(ax[idx][2], path=cur_path, title=f\"Ground Truth\", cmap=cur_cmap)  # , vmax=100)\n",
    "\n",
    "for idx, cur_path in enumerate(pred_model):\n",
    "    plot(ax[idx][3], path=cur_path, title=f\"Difference\", sub_image=real[idx], cmap=cur_cmap)\n",
    "\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616f9ba4",
   "metadata": {},
   "source": [
    "Little check with another lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89d8571",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "img = Image.open(pred_model[0])\n",
    "print(img.getpixel((0, 0)))\n",
    "print(img.getchannel(0))\n",
    "np_img = np.array(img)\n",
    "print(f\"{np_img.min()=}, {np_img.max()=}\")\n",
    "ips.img.imshow(np_img, size=4, axis_off=True, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0e0ee4",
   "metadata": {},
   "source": [
    "Another CMaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563fc44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 5\n",
    "\n",
    "input_samples, real, pred_model, ids = get_same_pred_real_samples(f\"{output_dir_cleaned}/pred\",\n",
    "                                                                  f\"{output_dir_cleaned}/real\",\n",
    "                                                                  f\"{output_dir_cleaned}/osm\",\n",
    "                                                                  n_samples)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(nrows=n_samples, ncols=4, figsize=(4*4, n_samples*6))\n",
    "# ax = ax.ravel()\n",
    "\n",
    "ax_idx = 0\n",
    "\n",
    "for idx, cur_path in enumerate(input_samples):\n",
    "    plot(ax[idx][0], path=cur_path, title=f\"Input\", cmap=\"gray\")\n",
    "\n",
    "for idx, cur_path in enumerate(pred_model):\n",
    "    plot(ax[idx][1], path=cur_path, title=f\"Model Prediction\", cmap=\"unique_hsv\")\n",
    "\n",
    "for idx, cur_path in enumerate(real):\n",
    "    plot(ax[idx][2], path=cur_path, title=f\"ground truth\", cmap=\"unique_hsv\")\n",
    "\n",
    "for idx, cur_path in enumerate(pred_model):\n",
    "    plot(ax[idx][3], path=cur_path, title=f\"Difference\", sub_image=real[idx])\n",
    "\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314e3f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=n_samples, ncols=2, figsize=(2*4, n_samples*6))\n",
    "# ax = ax.ravel()\n",
    "\n",
    "ax_idx = 0\n",
    "\n",
    "for idx, cur_path in enumerate(pred_model):\n",
    "    plot(ax[idx][0], path=cur_path, title=f\"Model Prediction\")\n",
    "\n",
    "for idx, cur_path in enumerate(real):\n",
    "    plot(ax[idx][1], path=cur_path, title=f\"ground truth\")\n",
    "\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f753d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=n_samples, ncols=1, figsize=(1*4, n_samples*6))\n",
    "\n",
    "for idx, cur_path in enumerate(pred_model):\n",
    "    plot(ax[idx], path=cur_path, title=f\"Model Prediction\", sub_image=real[idx], cmap=\"plasma\")\n",
    "\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd79486",
   "metadata": {},
   "source": [
    "Inspect some single images in more detail here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ec73f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.measure import block_reduce\n",
    "\n",
    "def plot_image_with_values(img, block_size=8):\n",
    "    # Compute mean over non-overlapping blocks\n",
    "    mean_img = block_reduce(img, block_size=(block_size, block_size), func=np.mean)\n",
    "    max_value = mean_img.max()\n",
    "\n",
    "    # Plot the mean image\n",
    "    plt.imshow(mean_img, cmap='gray', interpolation='nearest')\n",
    "    plt.colorbar(label='Mean Value')\n",
    "\n",
    "    # Annotate each block with the mean\n",
    "    for i in range(mean_img.shape[0]):\n",
    "        for j in range(mean_img.shape[1]):\n",
    "            val = mean_img[i, j]\n",
    "            color = 'white' if val < max_value/1.5 else 'black'\n",
    "            # color = int(255 - val)\n",
    "            plt.text(j, i, f'{val:.1f}', ha='center', va='center',\n",
    "                     color=color, fontsize=6)\n",
    "\n",
    "    plt.title(f'Mean Values over {block_size}x{block_size} Blocks')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0560b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = pred_model[0]\n",
    "img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE).astype(float)\n",
    "\n",
    "ips.img.imshow(img, size=4, axis_off=True, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1636385b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ips.img.plot_image_with_values(img, block_size=8, cmap='gray', title=None, \n",
    "                               font_size=6, save_to=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaec3523",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = plot(None, path=pred_model[0], title=f\"Model Prediction\", sub_image=real[idx], plot=False)\n",
    "ips.img.show_image_with_line_and_profile([img], axis='row', index=None, titles=None, figsize=(10, 4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "img-to-img",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
