{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "6033a71a",
      "metadata": {
        "id": "6033a71a"
      },
      "source": [
        "# Image-to-Image\n",
        "\n",
        "### In Google Coolab\n",
        "\n",
        "Go to settings and choose a GPU as device!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4307b2df",
      "metadata": {
        "id": "4307b2df"
      },
      "source": [
        "---\n",
        "### Install all requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "a331707c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a331707c",
        "outputId": "1e7e25bc-f660-4118-e451-633754bedc42",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "%pip install --no-cache-dir image-to-image==0.3"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a6f3a895",
      "metadata": {
        "id": "a6f3a895"
      },
      "source": [
        "---\n",
        "### Check Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "7d1c5304",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7d1c5304",
        "outputId": "220686d0-5e34-480b-e97c-9dbe6dd5d0ce",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "import prime_printer as prime\n",
        "\n",
        "print(prime.get_hardware());"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "22e6eabc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22e6eabc",
        "outputId": "a6438e6f-6d93-4944-be96-ba8ad6395f71",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "print('gpu' if torch.cuda.is_available() else 'cpu');"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6iJEVMPvlg5h",
      "metadata": {
        "id": "6iJEVMPvlg5h"
      },
      "source": [
        "### Setup Google Drive Link"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FkvMOpIhlnSz",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FkvMOpIhlnSz",
        "outputId": "f3926bbe-84a5-41f5-afee-cca883e89231"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.makedirs(\"./img-to-img\", exist_ok=True)\n",
        "os.listdir(\".\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81SFlhWDlj9a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81SFlhWDlj9a",
        "outputId": "fd5a2cb9-ab98-47b3-b116-47fb68ffd11e"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea756136",
      "metadata": {
        "id": "ea756136"
      },
      "source": [
        "---\n",
        "### Run Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "5otiAJQJtMwb",
      "metadata": {
        "id": "5otiAJQJtMwb"
      },
      "outputs": [],
      "source": [
        "code = \"import sys\\n\"\n",
        "code += \"from image_to_image import main\\n\"\n",
        "code += \"main()\\n\"\n",
        "\n",
        "with open(\"./main.py\", \"w\") as f:\n",
        "  f.write(code)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf841d0e",
      "metadata": {
        "id": "bf841d0e"
      },
      "source": [
        "Set the parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "d71ea178",
      "metadata": {
        "id": "d71ea178",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "device = None\n",
        "\n",
        "#######################\n",
        "# Training Parameters #\n",
        "#######################\n",
        "checkpoint_save_dir = \"./img-to-img/checkpoints\"\n",
        "save_only_best_model = False\n",
        "checkpoint_interval = 5\n",
        "validation_interval = 5\n",
        "epochs = 50\n",
        "batch_size = 8\n",
        "lr = 1e-4\n",
        "loss = \"l1\"   # 'l1', 'crossentropy', 'weighted_combined'\n",
        "\n",
        "# WeightedCombinedLoss\n",
        "wc_loss_silog_lambda = 0.5\n",
        "wc_loss_weight_silog = 0.5\n",
        "wc_loss_weight_grad = 10.0\n",
        "wc_loss_weight_ssim = 5.0\n",
        "wc_loss_weight_edge_aware = 10.0\n",
        "wc_loss_weight_l1 = 1.0\n",
        "wc_loss_weight_var = 1.0\n",
        "wc_loss_weight_range = 1.0\n",
        "wc_loss_weight_blur = 1.0\n",
        "\n",
        "# WeightedCombinedLoss 2\n",
        "wc_loss_silog_lambda_2 = 0.5\n",
        "wc_loss_weight_silog_2 = 0.5\n",
        "wc_loss_weight_grad_2 = 10.0\n",
        "wc_loss_weight_ssim_2 = 5.0\n",
        "wc_loss_weight_edge_aware_2 = 10.0\n",
        "wc_loss_weight_l1_2 = 1.0\n",
        "wc_loss_weight_var_2 = 1.0\n",
        "wc_loss_weight_range_2 = 1.0\n",
        "wc_loss_weight_blur_2 = 1.0\n",
        "\n",
        "optimizer = \"adam\"     # 'adam', 'adamw'\n",
        "optimizer_2 = \"adam\"   # second model part\n",
        "\n",
        "weight_decay = False\n",
        "weight_decay_rate = 0.0005\n",
        "\n",
        "gradient_clipping = False\n",
        "gradient_clipping_threshold = 0.5\n",
        "\n",
        "scheduler = \"step\"     # 'step', 'cosine'\n",
        "scheduler_2 = \"step\"   # second model part\n",
        "\n",
        "use_warm_up = False\n",
        "warm_up_start_lr = 0.00005\n",
        "warm_up_step_duration = 1000\n",
        "\n",
        "activate_amp = False\n",
        "amp_scaler = None  # or \"grad\"\n",
        "\n",
        "model = \"resfcn\"    # 'resfcn', 'pix2pix', 'residual_design_model', 'physicsformer'\n",
        "\n",
        "# --- ResFCN model ---\n",
        "resfcn_in_channels = 1\n",
        "resfcn_hidden_channels = 64\n",
        "resfcn_out_channels = 1\n",
        "resfcn_num_blocks = 16\n",
        "\n",
        "# --- Pix2Pix model ---\n",
        "pix2pix_in_channels = 1\n",
        "pix2pix_hidden_channels = 64\n",
        "pix2pix_out_channels = 1\n",
        "pix2pix_second_loss_lambda = 100.0\n",
        "\n",
        "# --- PhysicsFormer model ---\n",
        "physicsformer_in_channels = 1\n",
        "physicsformer_out_channels = 1\n",
        "physicsformer_img_size = 256\n",
        "physicsformer_patch_size = 4\n",
        "physicsformer_embedded_dim = 1024\n",
        "physicsformer_num_blocks = 8\n",
        "physicsformer_heads = 16\n",
        "physicsformer_mlp_dim = 2048\n",
        "physicsformer_dropout = 0.1\n",
        "\n",
        "# --- Residual Design model ---\n",
        "base_model = \"pix2pix\"     # 'resfcn', 'pix2pix'\n",
        "complex_model = \"pix2pix\"  # 'resfcn', 'pix2pix'\n",
        "combine_mode = \"nn\"        # 'math', 'nn'\n",
        "loss_2 = \"l1\"              # second loss\n",
        "\n",
        "# --- ResFCN model 2 ---\n",
        "resfcn_2_in_channels = 1\n",
        "resfcn_2_hidden_channels = 64\n",
        "resfcn_2_out_channels = 1\n",
        "resfcn_2_num_blocks = 16\n",
        "\n",
        "# --- Pix2Pix model 2 ---\n",
        "pix2pix_2_in_channels = 1\n",
        "pix2pix_2_hidden_channels = 64\n",
        "pix2pix_2_out_channels = 1\n",
        "pix2pix_2_second_loss_lambda = 100.0\n",
        "\n",
        "# --- PhysicsFormer model 2 ---\n",
        "physicsformer_in_channels_2 = 1\n",
        "physicsformer_out_channels_2 = 1\n",
        "physicsformer_img_size_2 = 256\n",
        "physicsformer_patch_size_2 = 4\n",
        "physicsformer_embedded_dim_2 = 1026\n",
        "physicsformer_num_blocks_2 = 8\n",
        "physicsformer_heads_2 = 16\n",
        "physicsformer_mlp_dim_2 = 2048\n",
        "physicsformer_dropout_2 = 0.1\n",
        "\n",
        "\n",
        "\n",
        "########################\n",
        "# Inference Parameters #\n",
        "########################\n",
        "model_params_path = None\n",
        "image_dir_path = None\n",
        "output_dir = \"./data/eval\"\n",
        "\n",
        "\n",
        "\n",
        "###################\n",
        "# Data Parameters #\n",
        "###################\n",
        "data_variation = \"sound_baseline\"\n",
        "input_type = \"osm\"\n",
        "output_type = \"standard\"\n",
        "\n",
        "fake_rgb_output = False\n",
        "make_14_dividable_size = False\n",
        "reflexion_channels = False\n",
        "reflexion_steps = 36\n",
        "reflexions_as_channels = False\n",
        "\n",
        "\n",
        "\n",
        "#######################\n",
        "# Experiment Tracking #\n",
        "#######################\n",
        "experiment_name = \"image-to-image\"\n",
        "run_name = \"image-to-image\"\n",
        "tensorboard_path = \"./img-to-img/tensorboard\"\n",
        "save_path = \"./img-to-img/train_inference\"\n",
        "cmap = \"gray\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "211011a8",
      "metadata": {
        "id": "211011a8"
      },
      "source": [
        "Run the training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4b7edf4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4b7edf4",
        "outputId": "4224c30e-3428-49a8-c473-cc5b2f8f8cf6",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# python -m image_to_image.main\n",
        "command = (\n",
        "    f\"python -m image_to_image.main \"\n",
        "    f\"--mode train \"\n",
        "    f\"--checkpoint_save_dir {checkpoint_save_dir} \"\n",
        "    f\"--checkpoint_interval {checkpoint_interval} \"\n",
        "    f\"--validation_interval {validation_interval} \"\n",
        "    f\"--epochs {epochs} \"\n",
        "    f\"--batch_size {batch_size} \"\n",
        "    f\"--lr {lr} \"\n",
        "    f\"--loss {loss} \"\n",
        "    f\"--wc_loss_silog_lambda {wc_loss_silog_lambda} \"\n",
        "    f\"--wc_loss_weight_silog {wc_loss_weight_silog} \"\n",
        "    f\"--wc_loss_weight_grad {wc_loss_weight_grad} \"\n",
        "    f\"--wc_loss_weight_ssim {wc_loss_weight_ssim} \"\n",
        "    f\"--wc_loss_weight_edge_aware {wc_loss_weight_edge_aware} \"\n",
        "    f\"--wc_loss_weight_l1 {wc_loss_weight_l1} \"\n",
        "    f\"--wc_loss_weight_var {wc_loss_weight_var} \"\n",
        "    f\"--wc_loss_weight_range {wc_loss_weight_range} \"\n",
        "    f\"--wc_loss_weight_blur {wc_loss_weight_blur} \"\n",
        "    f\"--optimizer {optimizer} \"\n",
        "    f\"--optimizer_2 {optimizer_2} \"\n",
        "    f\"--weight_decay_rate {weight_decay_rate} \"\n",
        "    f\"--gradient_clipping_threshold {gradient_clipping_threshold} \"\n",
        "    f\"--scheduler {scheduler} \"\n",
        "    f\"--scheduler_2 {scheduler_2} \"\n",
        "    f\"--warm_up_start_lr {warm_up_start_lr} \"\n",
        "    f\"--warm_up_step_duration {warm_up_step_duration} \"\n",
        "    f\"--amp_scaler {amp_scaler} \"\n",
        "    f\"--model_params_path {model_params_path} \"\n",
        "    f\"--image_dir_path {image_dir_path} \"\n",
        "    f\"--output_dir {output_dir} \"\n",
        "    f\"--model {model} \"\n",
        "    f\"--resfcn_in_channels {resfcn_in_channels} \"\n",
        "    f\"--resfcn_hidden_channels {resfcn_hidden_channels} \"\n",
        "    f\"--resfcn_out_channels {resfcn_out_channels} \"\n",
        "    f\"--resfcn_num_blocks {resfcn_num_blocks} \"\n",
        "    f\"--pix2pix_in_channels {pix2pix_in_channels} \"\n",
        "    f\"--pix2pix_hidden_channels {pix2pix_hidden_channels} \"\n",
        "    f\"--pix2pix_out_channels {pix2pix_out_channels} \"\n",
        "    f\"--pix2pix_second_loss_lambda {pix2pix_second_loss_lambda} \"\n",
        "    f\"--physicsformer_in_channels {physicsformer_in_channels} \"\n",
        "    f\"--physicsformer_out_channels {physicsformer_out_channels} \"\n",
        "    f\"--physicsformer_img_size {physicsformer_img_size} \"\n",
        "    f\"--physicsformer_patch_size {physicsformer_patch_size} \"\n",
        "    f\"--physicsformer_embedded_dim {physicsformer_embedded_dim} \"\n",
        "    f\"--physicsformer_num_blocks {physicsformer_num_blocks} \"\n",
        "    f\"--physicsformer_heads {physicsformer_heads} \"\n",
        "    f\"--physicsformer_mlp_dim {physicsformer_mlp_dim} \"\n",
        "    f\"--physicsformer_dropout {physicsformer_dropout} \"\n",
        "    f\"--base_model {base_model} \"\n",
        "    f\"--complex_model {complex_model} \"\n",
        "    f\"--combine_mode {combine_mode} \"\n",
        "    f\"--loss_2 {loss_2} \"\n",
        "    f\"--wc_loss_silog_lambda_2 {wc_loss_silog_lambda_2} \"\n",
        "    f\"--wc_loss_weight_silog_2 {wc_loss_weight_silog_2} \"\n",
        "    f\"--wc_loss_weight_grad_2 {wc_loss_weight_grad_2} \"\n",
        "    f\"--wc_loss_weight_ssim_2 {wc_loss_weight_ssim_2} \"\n",
        "    f\"--wc_loss_weight_edge_aware_2 {wc_loss_weight_edge_aware_2} \"\n",
        "    f\"--wc_loss_weight_l1_2 {wc_loss_weight_l1_2} \"\n",
        "    f\"--wc_loss_weight_var_2 {wc_loss_weight_var_2} \"\n",
        "    f\"--wc_loss_weight_range_2 {wc_loss_weight_range_2} \"\n",
        "    f\"--wc_loss_weight_blur_2 {wc_loss_weight_blur_2} \"\n",
        "    f\"--resfcn_2_in_channels {resfcn_2_in_channels} \"\n",
        "    f\"--resfcn_2_hidden_channels {resfcn_2_hidden_channels} \"\n",
        "    f\"--resfcn_2_out_channels {resfcn_2_out_channels} \"\n",
        "    f\"--resfcn_2_num_blocks {resfcn_2_num_blocks} \"\n",
        "    f\"--pix2pix_2_in_channels {pix2pix_2_in_channels} \"\n",
        "    f\"--pix2pix_2_hidden_channels {pix2pix_2_hidden_channels} \"\n",
        "    f\"--pix2pix_2_out_channels {pix2pix_2_out_channels} \"\n",
        "    f\"--pix2pix_2_second_loss_lambda {pix2pix_2_second_loss_lambda} \"\n",
        "    f\"--physicsformer_in_channels_2 {physicsformer_in_channels_2} \"\n",
        "    f\"--physicsformer_out_channels_2 {physicsformer_out_channels_2} \"\n",
        "    f\"--physicsformer_img_size_2 {physicsformer_img_size_2} \"\n",
        "    f\"--physicsformer_patch_size_2 {physicsformer_patch_size_2} \"\n",
        "    f\"--physicsformer_embedded_dim_2 {physicsformer_embedded_dim_2} \"\n",
        "    f\"--physicsformer_num_blocks_2 {physicsformer_num_blocks_2} \"\n",
        "    f\"--physicsformer_heads_2 {physicsformer_heads_2} \"\n",
        "    f\"--physicsformer_mlp_dim_2 {physicsformer_mlp_dim_2} \"\n",
        "    f\"--physicsformer_dropout_2 {physicsformer_dropout_2} \"\n",
        "    f\"--data_variation {data_variation} \"\n",
        "    f\"--input_type {input_type} \"\n",
        "    f\"--output_type {output_type} \"\n",
        ")\n",
        "\n",
        "if save_only_best_model:\n",
        "  command += f\"--save_only_best_model \"\n",
        "\n",
        "if weight_decay:\n",
        "  command += f\"--weight_decay \"\n",
        "\n",
        "if gradient_clipping:\n",
        "  command += f\"--gradient_clipping \"\n",
        "\n",
        "if use_warm_up:\n",
        "  command += f\"--use_warm_up \"\n",
        "\n",
        "if activate_amp:\n",
        "  command += \"--activate_amp \"\n",
        "\n",
        "if fake_rgb_output:\n",
        "    command += \"--fake_rgb_output \"\n",
        "\n",
        "if make_14_dividable_size:\n",
        "    command += \"--make_14_dividable_size \"\n",
        "\n",
        "if reflexion_channels:\n",
        "    command += f\"--reflexion_channels --reflexion_steps {reflexion_steps} \"\n",
        "    if reflexions_as_channels:\n",
        "        command += \"--reflexions_as_channels \"\n",
        "\n",
        "command += f\"--device {device} \"\n",
        "command += f\"--experiment_name {experiment_name} \"\n",
        "command += f\"--run_name {run_name} \"\n",
        "command += f\"--tensorboard_path {tensorboard_path} \"\n",
        "command += f\"--save_path {save_path} \"\n",
        "command += f\"--cmap {cmap} \"\n",
        "\n",
        "# Run it\n",
        "!{command}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1BOyK_KlX9G",
      "metadata": {
        "id": "a1BOyK_KlX9G"
      },
      "source": [
        "### Save checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Pb_8lYI0lbJf",
      "metadata": {
        "id": "Pb_8lYI0lbJf"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "\n",
        "source = \"/content/img-to-img\"  # folder in Colab\n",
        "destination = \"/content/drive/MyDrive/img-to-img\"  # target folder in Drive\n",
        "\n",
        "shutil.copytree(source, destination)\n",
        "print(\"Folder uploaded to Google Drive!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc3e847f",
      "metadata": {
        "id": "bc3e847f"
      },
      "source": [
        "---\n",
        "### Run Test"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c11a1ed",
      "metadata": {
        "id": "3c11a1ed"
      },
      "source": [
        "You might to add the specific save path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bde70ecd",
      "metadata": {
        "id": "bde70ecd",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "########################\n",
        "# Inference Parameters #\n",
        "########################\n",
        "model_params_path = None\n",
        "image_dir_path = None\n",
        "output_dir = \"../../data/eval\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "386c864b",
      "metadata": {
        "id": "386c864b",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# python -m image_to_image.main\n",
        "command = (\n",
        "    f\"python -m image_to_image.main \"\n",
        "    f\"--mode test \"\n",
        "    f\"--checkpoint_save_dir {checkpoint_save_dir} \"\n",
        "    f\"--checkpoint_interval {checkpoint_interval} \"\n",
        "    f\"--validation_interval {validation_interval} \"\n",
        "    f\"--epochs {epochs} \"\n",
        "    f\"--batch_size {batch_size} \"\n",
        "    f\"--lr {lr} \"\n",
        "    f\"--loss {loss} \"\n",
        "    f\"--wc_loss_silog_lambda {wc_loss_silog_lambda} \"\n",
        "    f\"--wc_loss_weight_silog {wc_loss_weight_silog} \"\n",
        "    f\"--wc_loss_weight_grad {wc_loss_weight_grad} \"\n",
        "    f\"--wc_loss_weight_ssim {wc_loss_weight_ssim} \"\n",
        "    f\"--wc_loss_weight_edge_aware {wc_loss_weight_edge_aware} \"\n",
        "    f\"--wc_loss_weight_l1 {wc_loss_weight_l1} \"\n",
        "    f\"--wc_loss_weight_var {wc_loss_weight_var} \"\n",
        "    f\"--wc_loss_weight_range {wc_loss_weight_range} \"\n",
        "    f\"--wc_loss_weight_blur {wc_loss_weight_blur} \"\n",
        "    f\"--optimizer {optimizer} \"\n",
        "    f\"--optimizer_2 {optimizer_2} \"\n",
        "    f\"--weight_decay_rate {weight_decay_rate} \"\n",
        "    f\"--gradient_clipping_threshold {gradient_clipping_threshold} \"\n",
        "    f\"--scheduler {scheduler} \"\n",
        "    f\"--scheduler_2 {scheduler_2} \"\n",
        "    f\"--warm_up_start_lr {warm_up_start_lr} \"\n",
        "    f\"--warm_up_step_duration {warm_up_step_duration} \"\n",
        "    f\"--amp_scaler {amp_scaler} \"\n",
        "    f\"--model_params_path {model_params_path} \"\n",
        "    f\"--image_dir_path {image_dir_path} \"\n",
        "    f\"--output_dir {output_dir} \"\n",
        "    f\"--model {model} \"\n",
        "    f\"--resfcn_in_channels {resfcn_in_channels} \"\n",
        "    f\"--resfcn_hidden_channels {resfcn_hidden_channels} \"\n",
        "    f\"--resfcn_out_channels {resfcn_out_channels} \"\n",
        "    f\"--resfcn_num_blocks {resfcn_num_blocks} \"\n",
        "    f\"--pix2pix_in_channels {pix2pix_in_channels} \"\n",
        "    f\"--pix2pix_hidden_channels {pix2pix_hidden_channels} \"\n",
        "    f\"--pix2pix_out_channels {pix2pix_out_channels} \"\n",
        "    f\"--pix2pix_second_loss_lambda {pix2pix_second_loss_lambda} \"\n",
        "    f\"--physicsformer_in_channels {physicsformer_in_channels} \"\n",
        "    f\"--physicsformer_out_channels {physicsformer_out_channels} \"\n",
        "    f\"--physicsformer_img_size {physicsformer_img_size} \"\n",
        "    f\"--physicsformer_patch_size {physicsformer_patch_size} \"\n",
        "    f\"--physicsformer_embedded_dim {physicsformer_embedded_dim} \"\n",
        "    f\"--physicsformer_num_blocks {physicsformer_num_blocks} \"\n",
        "    f\"--physicsformer_heads {physicsformer_heads} \"\n",
        "    f\"--physicsformer_mlp_dim {physicsformer_mlp_dim} \"\n",
        "    f\"--physicsformer_dropout {physicsformer_dropout} \"\n",
        "    f\"--base_model {base_model} \"\n",
        "    f\"--complex_model {complex_model} \"\n",
        "    f\"--combine_mode {combine_mode} \"\n",
        "    f\"--loss_2 {loss_2} \"\n",
        "    f\"--wc_loss_silog_lambda_2 {wc_loss_silog_lambda_2} \"\n",
        "    f\"--wc_loss_weight_silog_2 {wc_loss_weight_silog_2} \"\n",
        "    f\"--wc_loss_weight_grad_2 {wc_loss_weight_grad_2} \"\n",
        "    f\"--wc_loss_weight_ssim_2 {wc_loss_weight_ssim_2} \"\n",
        "    f\"--wc_loss_weight_edge_aware_2 {wc_loss_weight_edge_aware_2} \"\n",
        "    f\"--wc_loss_weight_l1_2 {wc_loss_weight_l1_2} \"\n",
        "    f\"--wc_loss_weight_var_2 {wc_loss_weight_var_2} \"\n",
        "    f\"--wc_loss_weight_range_2 {wc_loss_weight_range_2} \"\n",
        "    f\"--wc_loss_weight_blur_2 {wc_loss_weight_blur_2} \"\n",
        "    f\"--resfcn_2_in_channels {resfcn_2_in_channels} \"\n",
        "    f\"--resfcn_2_hidden_channels {resfcn_2_hidden_channels} \"\n",
        "    f\"--resfcn_2_out_channels {resfcn_2_out_channels} \"\n",
        "    f\"--resfcn_2_num_blocks {resfcn_2_num_blocks} \"\n",
        "    f\"--pix2pix_2_in_channels {pix2pix_2_in_channels} \"\n",
        "    f\"--pix2pix_2_hidden_channels {pix2pix_2_hidden_channels} \"\n",
        "    f\"--pix2pix_2_out_channels {pix2pix_2_out_channels} \"\n",
        "    f\"--pix2pix_2_second_loss_lambda {pix2pix_2_second_loss_lambda} \"\n",
        "    f\"--physicsformer_in_channels_2 {physicsformer_in_channels_2} \"\n",
        "    f\"--physicsformer_out_channels_2 {physicsformer_out_channels_2} \"\n",
        "    f\"--physicsformer_img_size_2 {physicsformer_img_size_2} \"\n",
        "    f\"--physicsformer_patch_size_2 {physicsformer_patch_size_2} \"\n",
        "    f\"--physicsformer_embedded_dim_2 {physicsformer_embedded_dim_2} \"\n",
        "    f\"--physicsformer_num_blocks_2 {physicsformer_num_blocks_2} \"\n",
        "    f\"--physicsformer_heads_2 {physicsformer_heads_2} \"\n",
        "    f\"--physicsformer_mlp_dim_2 {physicsformer_mlp_dim_2} \"\n",
        "    f\"--physicsformer_dropout_2 {physicsformer_dropout_2} \"\n",
        "    f\"--data_variation {data_variation} \"\n",
        "    f\"--input_type {input_type} \"\n",
        "    f\"--output_type {output_type} \"\n",
        ")\n",
        "\n",
        "if save_only_best_model:\n",
        "  command += f\"--save_only_best_model \"\n",
        "\n",
        "if weight_decay:\n",
        "  command += f\"--weight_decay \"\n",
        "\n",
        "if gradient_clipping:\n",
        "  command += f\"--gradient_clipping \"\n",
        "\n",
        "if use_warm_up:\n",
        "  command += f\"--use_warm_up \"\n",
        "\n",
        "if activate_amp:\n",
        "  command += \"--activate_amp \"\n",
        "\n",
        "if fake_rgb_output:\n",
        "    command += \"--fake_rgb_output \"\n",
        "\n",
        "if make_14_dividable_size:\n",
        "    command += \"--make_14_dividable_size \"\n",
        "\n",
        "if reflexion_channels:\n",
        "    command += f\"--reflexion_channels --reflexion_steps {reflexion_steps} \"\n",
        "    if reflexions_as_channels:\n",
        "        command += \"--reflexions_as_channels \"\n",
        "\n",
        "command += f\"--device {device} \"\n",
        "command += f\"--experiment_name {experiment_name} \"\n",
        "command += f\"--run_name {run_name} \"\n",
        "command += f\"--tensorboard_path {tensorboard_path} \"\n",
        "command += f\"--save_path {save_path} \"\n",
        "command += f\"--cmap {cmap} \"\n",
        "\n",
        "# Run it\n",
        "!{command}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd86f006",
      "metadata": {
        "id": "bd86f006"
      },
      "source": [
        "Next Steps:\n",
        "Save the weights locally and run the evaluation notebook locally.\n",
        "\n",
        "https://github.com/xXAI-botXx/Image-to-Image/blob/main/image_to_image/model_interactions/eval_physgen_benchmark.ipynb"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
